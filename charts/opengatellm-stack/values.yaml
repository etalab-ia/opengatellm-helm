global:
  storage:
    storageClassName: sbs-default

# values for opengateLLM chart (enabled, postgres, redis)
opengatellm-core:
  enabled: true
  postgresql:
    cluster:
      initdb:
        postInitApplicationSQL:
          - CREATE DATABASE playground WITH ENCODING 'UTF8';

  # values for opengateLLM
  opengatellmCore:
    replicas: 1
    image:
      repository: ghcr.io/etalab-ia/opengatellm/api
      tag: 0.3.6
      pullPolicy: IfNotPresent
    service:
      type: ClusterIP
      port: 8000
    logging:
      level: "INFO"

    models:
      - name: albert-testbed
        type: text-generation
        providers:
          - type: vllm
            model_name: "gemma3:1b"
            url: "http://albert-testbed.etalab.gouv.fr:8000"
            key: "changeme"

      - name: mistralai/Mistral-Small-3.2-24B-Instruct-2506
        type: text-generation
        providers:
          - type: vllm
            model_name: "mistralai/Mistral-Small-3.2-24B-Instruct-2506"
            url: "http://opengatellm-router-service/"
            key: "changeme"

      # If embeddings are deployed through vLLM, use this version :
#      - name: BAAI/bge-m3
#        type: text-embeddings-inference
#        providers:
#          - type: vllm
#            model_name: "BAAI/bge-m3"
#            url: "http://opengatellm-router-service/"
#            key: "changeme"

      # If embeddings are deployed through TEI, use this version :
      - name: BAAI/bge-m3
        type: text-embeddings-inference
        dimensions: 1024
        providers:
          - type: tei
            model_name: "BAAI/bge-m3"
            url: "http://opengatellm-stack-embeddings/"
            key: "changeme"

    structuredConfig:
      dependencies:
        postgres:
          url: ${POSTGRES_URI}
          echo: False
          pool_size: 5
          connect_args:
            server_settings:
              statement_timeout: "120s"
            command_timeout: 60
        redis:
          url: redis://:${REDIS_PASSWORD}@${REDIS_HOST}:${REDIS_PORT}

        elasticsearch:
          hosts: "http://opengatellm-elasticsearch-es-http:9200"

      settings:
        log_level: INFO
        vector_store_model: "BAAI/bge-m3"

      playground:
        api_url: "http://opengatellm-core:8000"
        app_title: "OpenGateLLM"
        default_model: ""
        encryption_key: "changeme"
        session_secret_key: "changeme"
        proconnect_enabled: false
        postgres:
          url: postgresql+asyncpg://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/playground
        theme_accent_color: "purple"
        theme_appearance: "light"
        theme_gray_color: "gray"
        theme_has_background: true
        theme_panel_background: "solid"
        theme_radius: "medium"
        theme_scaling: "100%"

    probes:
      readiness:
        httpGet:
          path: /health
          port: http
        initialDelaySeconds: 40
        periodSeconds: 15
      liveness:
        httpGet:
          path: /health
          port: http
        initialDelaySeconds: 120
        periodSeconds: 30

playground:
  replicas: 1
  image:
    repository: ghcr.io/etalab-ia/opengatellm/playground
    tag: 0.3.6
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 80
    targetPort: 8501
  probes:
    readiness:
      path: /
      initialDelaySeconds: 5
      periodSeconds: 10
    liveness:
      path: /
      initialDelaySeconds: 10
      periodSeconds: 10
  config:
    api_url: "http://opengatellm-core:8000"
    default_model: ""
    postgres:
      url: postgresql+asyncpg://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/playground

vllm-stack:
  enabled: true
  routerSpec:
    serviceType: ClusterIP
    servicePort: 80
    resources:
      requests:
        cpu: 400m
        memory: 1Gi
      limits:
        memory: 2Gi
  servingEngineSpec:
    enableEngine: true
    vllmApiKey: "changeme"
    modelSpec:
      - name: "mistral-small"
        repository: vllm/vllm-openai
        tag: v0.11.0
        imagePullPolicy: IfNotPresent
        modelURL: mistralai/Mistral-Small-3.2-24B-Instruct-2506

        replicaCount: 1
        requestCPU: 20
        requestMemory: "200G"
        requestGPU: 1
        limitCPU: "22"
        limitMemory: "230G"

        pvcStorage: "230Gi"
        storageClass: sbs-default
        pvcAccessMode:
          - ReadWriteOnce

        shmSize: "32Gi"

        vllmConfig:
          tensorParallelSize: 1
          enablePrefixCaching: false
          extraArgs:
            - "--tokenizer_mode"
            - "mistral"
            - "--config_format"
            - "mistral"
            - "--load_format"
            - "mistral"
            - "--tool-call-parser"
            - "mistral"
            - "--enable-auto-tool-choice"

        hf_token:
          secretName: "huggingface-token"
          secretKey: "token"

embeddings:
  enabled: true
  replicas: 1
  image:
    repository: ghcr.io/huggingface/text-embeddings-inference
    tag: cpu-latest
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 80
    targetPort: 8000
  config:
    model: BAAI/bge-m3
    port: 8000
  resources:
    limits:
      cpu: "4"
      memory: 28Gi
      gpu: 0
    requests:
      cpu: "2"
      memory: 16Gi
      gpu: 0
  probes:
    readiness:
      enabled: true
      path: /health
      initialDelaySeconds: 30
      periodSeconds: 120
    liveness:
      enabled: false
      path: /health
      initialDelaySeconds: 240
      periodSeconds: 30

huggingface:
  token: "changeme"

# ES deployment follows this recommended deployment : https://www.elastic.co/docs/deploy-manage/deploy/cloud-on-k8s/install-using-helm-chart
elasticsearch:
  enabled: true
  version: "9.0.8"
  replicas: 1
  resources:
    requests:
      cpu: "100m"
      memory: "1Gi"
    limits:
      cpu: "400m"
      memory: "4Gi"
  persistence:
    enabled: true
    size: 8Gi

eck-operator-crds:
  {}

eck-operator:
  installCRDs: false
  createClusterScopedResources: true
  webhook:
    enabled: false
  config:
    validateStorageClass: false

  resources:
    limits:
      cpu: 1
      memory: 1Gi
    requests:
      cpu: 100m
      memory: 150Mi