global:
  storage:
    storageClassName: default

opengatellm:
  enabled: true
  replicas: 1
  image:
    repository: ghcr.io/etalab-ia/opengatellm/api
    tag: 0.2.7
    pullPolicy: IfNotPresent
  service:
    type: LoadBalancer
    port: 80
    targetPort: 8000
  config:
    # ----------------------------------- models ------------------------------------
    models:
      - name: albert-testbed
        type: text-generation
        providers:
          - type: vllm
            model_name: "gemma3:1b"
            url: "http://albert-testbed.etalab.gouv.fr:8000"
            key: "changeme"

      - name: mistralai/Voxtral-Mini-3B-2507
        type: automatic-speech-recognition
        providers:
          - type: vllm
            model_name: "mistralai/Voxtral-Mini-3B-2507"
            # Note: Update service name based on your release name: <release-name>-vllm
            url: "http://opengatellm-stack-vllm/"
            key: "changeme"

      - name: mistralai/Mistral-Small-3.2-24B-Instruct-2506
        type: text-generation
        providers:
          - type: vllm
            model_name: "mistralai/Mistral-Small-3.2-24B-Instruct-2506"
            # Note: Update service name based on your release name: <release-name>-vllm
            url: "http://opengatellm-stack-vllm/"
            key: "changeme"

      - name: embeddings
        type: text-embeddings-inference
        providers:
          - type: tei
            model_name: "BAAI/bge-m3"
            url: "http://bge-embeddings.opengatellm.svc.cluster.local/"
            key: "changeme"

    # -------------------------------- dependencies ---------------------------------
    dependencies:
      postgres:
        # Note: Update service name based on your release name: <release-name>-postgresql
        url: "postgresql+asyncpg://postgres:changeme@opengatellm-stack-postgresql:5432/api"
        echo: False
        pool_size: 5
        connect_args:
          server_settings:
            statement_timeout: "120s"
          command_timeout: 60

      redis:
        # Note: Update service name based on your release name: <release-name>-redis-master
        host: opengatellm-stack-redis-master
        port: 6379
        password: changeme

      # playground ---------------------------------------------------------------------------------------------------------------------------------------
    playground:
      api_url: "http://opengatellm.opengatellm.svc.cluster.local"
      encryption_key: changeme
      session_secret_key: changeme
      proconnect_enabled: False
      postgres:
        # Note: Update service name based on your release name: <release-name>-postgresql
        url: postgresql+asyncpg://postgres:changeme@opengatellm-stack-postgresql:5432/playground

  probes:
    readiness:
      enabled: false
      path: /health
      initialDelaySeconds: 10
      periodSeconds: 30
    liveness:
      enabled: false
      path: /health
      initialDelaySeconds: 60
      periodSeconds: 30

streamlit:
  replicas: 1
  image:
    repository: ghcr.io/etalab-ia/opengatellm/playground
    tag: 0.2.7
    pullPolicy: IfNotPresent
  service:
    type: LoadBalancer
    port: 8501
    targetPort: 8501
  probes:
    readiness:
      path: /
      initialDelaySeconds: 5
      periodSeconds: 10
    liveness:
      path: /
      initialDelaySeconds: 10
      periodSeconds: 10

vllm:
  enabled: true
  replicas: 1
  api_key: "changeme"
  image:
    repository: vllm/vllm-openai
    tag: v0.11.0
    pullPolicy: IfNotPresent
  service:
    name: vllm-api
    type: LoadBalancer
    port: 80
    targetPort: 8000
  config:
    # model: neuralmagic/Meta-Llama-3.1-70B-Instruct-FP8
    # model: meta-llama/Llama-3.1-8B-Instruct
    # model: google/gemma-3-27b-it
    model: mistralai/Mistral-Small-3.2-24B-Instruct-2506
    # model: Qwen/Qwen3-30B-A3B-Instruct-2507
    # model: mistralai/Voxtral-Mini-3B-2507
    # model: mistralai/Magistral-Small-2506
    # --enable-auto-tool-choice --tool-call-parser llama3_json --chat-template examples/tool_chat_template_llama3.1_json.jinja
    serveArgs: "--tokenizer_mode mistral --config_format mistral --load_format mistral --tensor-parallel-size 1 --tool-call-parser mistral --enable-auto-tool-choice --no-enable-prefix-caching"
    # serveArgs: "--no-enable-prefix-caching --max-model-len 63440 --tool-call-parser openai --enable-auto-tool-choice"
    # serveArgs: "--reasoning-parser qwen3 --enable-auto-tool-choice --tool-call-parser hermes --max-model-len 132896 --tensor-parallel-size 1 --no-enable-prefix-caching"


  persistence:
    size: 230Gi
    storageClassName: sbs-default
  resources:
#    limits:
#      cpu: "44"
#      memory: 460G
#      gpu: 2
#    requests:
#      cpu: "40"
#      memory: 400G
#      gpu: 2
    limits:
      cpu: "22"
      memory: 230G
      gpu: 1
    requests:
      cpu: "20"
      memory: 200G
      gpu: 1
  shm:
    sizeLimit: 32Gi
  secrets:
    huggingfaceToken:
      name: huggingface-token
      key: token
    apiKey:
      name: opengatellm-stack-vllm-api-key
      key: api_key
  probes:
    readiness:
      path: /health
      initialDelaySeconds: 10
      periodSeconds: 30
    liveness:
      path: /health
      initialDelaySeconds: 300
      periodSeconds: 30

# BGE Embeddings configuration
embeddings:
  enabled: false
  replicas: 1
  image:
    repository: ghcr.io/huggingface/text-embeddings-inference
    tag: cpu-latest
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 80
    targetPort: 8000
  config:
    model: BAAI/bge-m3
    port: 8000
  resources:
    limits:
      cpu: "4"
      memory: 32Gi
      #gpu: 1
    requests:
      cpu: "2"
      memory: 16Gi
      #gpu: 1
  probes:
    readiness:
      path: /health
      initialDelaySeconds: 10
      periodSeconds: 30
    liveness:
      path: /health
      initialDelaySeconds: 60
      periodSeconds: 30

redis:
  enabled: true
  architecture: standalone
  auth:
    enabled: true
    password: "changeme"
  master:
    persistence:
      enabled: true
      size: 10Gi
    resources: {}
  replica:
    replicaCount: 0


postgresql:
  enabled: true
  auth:
    username: postgres
    password: changeme
    database: postgres
  primary:
    persistence:
      enabled: true
      size: 8Gi
    initdb:
      scripts:
        init-db.sql: |
          CREATE DATABASE api WITH ENCODING 'utf8';
    resources: {}