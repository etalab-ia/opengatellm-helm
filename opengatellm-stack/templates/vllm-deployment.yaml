{{- if .Values.vllm.enabled }}
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm
  labels:
    app: vllm
    {{- include "opengatellm-stack.labels" . | nindent 4 }}
    app.kubernetes.io/component: vllm
spec:
  replicas: {{ .Values.vllm.replicas }}
  selector:
    matchLabels:
      app: vllm
  template:
    metadata:
      labels:
        app: vllm
    spec:
      nodeSelector:
        k8s.scaleway.com/pool-name: "gpu"
      volumes:
      - name: cache-volume
        persistentVolumeClaim:
          claimName: vllm
      - name: shm
        emptyDir:
          medium: Memory
          sizeLimit: {{ .Values.vllm.shm.sizeLimit | quote }}
      containers:
      - name: vllm
        image: {{ .Values.vllm.image.repository }}:{{ .Values.vllm.image.tag }}
        imagePullPolicy: {{ .Values.vllm.image.pullPolicy }}
        command: ["/bin/sh", "-c"]
        args:
        - |
          VLLM_VERSION={{ .Values.vllm.image.tag | trimPrefix "v" }} &&
          pip install vllm[audio]==${VLLM_VERSION} &&
          vllm serve {{ .Values.vllm.config.model }} {{ .Values.vllm.config.serveArgs }}
        env:
        - name: HUGGING_FACE_HUB_TOKEN
          valueFrom:
            secretKeyRef:
              name: {{ .Values.vllm.secrets.huggingfaceToken.name }}
              key: {{ .Values.vllm.secrets.huggingfaceToken.key }}
        - name: VLLM_API_KEY
          valueFrom:
            secretKeyRef:
              name: {{ .Values.vllm.secrets.apiKey.name }}
              key: {{ .Values.vllm.secrets.apiKey.key }}
        ports:
        - containerPort: {{ .Values.vllm.service.targetPort }}
        resources:
          limits:
            cpu: {{ .Values.vllm.resources.limits.cpu | quote }}
            memory: {{ .Values.vllm.resources.limits.memory }}
            nvidia.com/gpu: {{ .Values.vllm.resources.limits.gpu }}
          requests:
            cpu: {{ .Values.vllm.resources.requests.cpu | quote }}
            memory: {{ .Values.vllm.resources.requests.memory }}
            nvidia.com/gpu: {{ .Values.vllm.resources.requests.gpu }}
        volumeMounts:
        - mountPath: /root/.cache/huggingface
          name: cache-volume
        - name: shm
          mountPath: /dev/shm
        readinessProbe:
          httpGet:
            path: {{ .Values.vllm.probes.readiness.path }}
            port: {{ .Values.vllm.service.targetPort }}
          initialDelaySeconds: {{ .Values.vllm.probes.readiness.initialDelaySeconds }}
          periodSeconds: {{ .Values.vllm.probes.readiness.periodSeconds }}
        livenessProbe:
          httpGet:
            path: {{ .Values.vllm.probes.liveness.path }}
            port: {{ .Values.vllm.service.targetPort }}
          initialDelaySeconds: {{ .Values.vllm.probes.liveness.initialDelaySeconds }}
          periodSeconds: {{ .Values.vllm.probes.liveness.periodSeconds }}
{{- end }}
