apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "vllm.fullname" . }}
  labels:
    {{- include "vllm.labels" . | nindent 4 }}
    app.kubernetes.io/component: vllm
spec:
  replicas: {{ .Values.replicas }}
  selector:
    matchLabels:
      {{- include "vllm.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      labels:
        {{- include "vllm.selectorLabels" . | nindent 8 }}
    spec:
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      volumes:
      - name: cache-volume
        persistentVolumeClaim:
          claimName: {{ include "vllm.fullname" . }}
      - name: shm
        emptyDir:
          medium: Memory
          sizeLimit: {{ .Values.shm.sizeLimit | quote }}
      containers:
      - name: vllm
        image: {{ .Values.image.repository }}:{{ .Values.image.tag }}
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        command: ["/bin/sh", "-c"]
        args:
        - |
          VLLM_VERSION={{ .Values.image.tag | trimPrefix "v" }} &&
          pip install vllm[audio]==${VLLM_VERSION} &&
          vllm serve {{ .Values.config.model }} {{ .Values.config.serveArgs }}
        env:
        - name: HUGGING_FACE_HUB_TOKEN
          valueFrom:
            secretKeyRef:
              name: {{ .Values.secrets.huggingfaceToken.name }}
              key: {{ .Values.secrets.huggingfaceToken.key }}
        - name: VLLM_API_KEY
          valueFrom:
            secretKeyRef:
              name: {{ .Values.secrets.apiKey.name }}
              key: {{ .Values.secrets.apiKey.key }}
        ports:
        - containerPort: {{ .Values.service.targetPort }}
        resources:
          limits:
            cpu: {{ .Values.resources.limits.cpu | quote }}
            memory: {{ .Values.resources.limits.memory }}
            nvidia.com/gpu: {{ .Values.resources.limits.gpu }}
          requests:
            cpu: {{ .Values.resources.requests.cpu | quote }}
            memory: {{ .Values.resources.requests.memory }}
            nvidia.com/gpu: {{ .Values.resources.requests.gpu }}
        volumeMounts:
        - mountPath: /root/.cache/huggingface
          name: cache-volume
        - name: shm
          mountPath: /dev/shm
        readinessProbe:
          httpGet:
            path: {{ .Values.probes.readiness.path }}
            port: {{ .Values.service.targetPort }}
          initialDelaySeconds: {{ .Values.probes.readiness.initialDelaySeconds }}
          periodSeconds: {{ .Values.probes.readiness.periodSeconds }}
        livenessProbe:
          httpGet:
            path: {{ .Values.probes.liveness.path }}
            port: {{ .Values.service.targetPort }}
          initialDelaySeconds: {{ .Values.probes.liveness.initialDelaySeconds }}
          periodSeconds: {{ .Values.probes.liveness.periodSeconds }}
